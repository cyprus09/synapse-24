{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enK69vGaSkIo",
        "outputId": "88ead997-5f23-4907-b357-b25c1358aeab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=Tz3vPkHeAeWYRsy5mEmtjsSLk6efCS&prompt=consent&token_usage=remote&access_type=offline&code_challenge=o-5afLkQuaq2-W8HuPuo7QN0kfwT-q0QFEmE6hHcXgU&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AanRRrswcfHciqMaf2LkFjBOOUYTyPViOiOS4cWHZohl1eJcV7il753k0ZIUOBR2mpbz1Q\n",
            "\n",
            "You are now logged in as [aryan20102002@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "Create in progress for [https://cloudresourcemanager.googleapis.com/v1/projects/synapse-copyright-detection].\n",
            "Enabling service [cloudapis.googleapis.com] on project [synapse-copyright-detection]...\n",
            "Operation \"operations/acat.p2-1040870637528-fe791440-f278-495f-9998-c17adb92208a\" finished successfully.\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth login\n",
        "# !gcloud projects create synapse-copyright-detection --name=\"Synapse Copyright Detection\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9J_qWB3VMvv",
        "outputId": "ceffc8d8-e604-462a-f929-d9ede6a4cbd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "!gcloud config set project synapse-copyright-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rurrXOAB5pV",
        "outputId": "05a36c92-1eff-41b1-8ffb-0ad7f53227b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.25.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.8.30)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.6.1)\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=nqB5Eph0nNu41cHqdFF4fO2XfE8qgB&prompt=consent&token_usage=remote&access_type=offline&code_challenge=KnSHAo59EHcfuY5cNM3cIXf7Uux_S_DgWnJ--T6xudw&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0AanRRruTPwh2FPb_yZ5UktymDJcqQgDgDj9kAtbFq5mQT_IbNwvGPGMQICDkt4HRUd_gKQ\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\n",
            "Quota project \"synapse-copyright-detection\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers torch torchaudio librosa opencv-python-headless faiss-cpu\n",
        "!pip install google-cloud-storage\n",
        "\n",
        "# Authenticate and enable Google Cloud SDK for YouTube-8M dataset\n",
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FU_Ppj5B-bH",
        "outputId": "5b23b78d-f475-4e60-855a-8d5b9ed8d352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  4450  100  4450    0     0  17234      0 --:--:-- --:--:-- --:--:-- 17248\n",
            "Resuming Download ...\n",
            "Files remaining 9\n",
            "Downloading: train3622.tfrecord\n",
            ">> Downloading http://us.data.yt8m.org/2/frame/train/train6A.tfrecord 100.0%Succesfully downloaded train3622.tfrecord 276401566 bytes. 69.5%\n",
            "Successfully downloaded train3622.tfrecord\n",
            "\n",
            "\n",
            "Downloading: train3519.tfrecord\n",
            ">> Downloading http://us.data.yt8m.org/2/frame/train/train4V.tfrecord 100.0%Succesfully downloaded train3519.tfrecord 265500722 bytes.\n",
            "Successfully downloaded train3519.tfrecord\n",
            "\n",
            "\n",
            "Downloading: train2791.tfrecord\n",
            ">> Downloading http://us.data.yt8m.org/2/frame/train/trainTb.tfrecord 100.0%Succesfully downloaded train2791.tfrecord 279130176 bytes.\n",
            "Successfully downloaded train2791.tfrecord\n",
            "\n",
            "\n",
            "Downloading: train0477.tfrecord\n",
            ">> Downloading http://us.data.yt8m.org/2/frame/train/trainhR.tfrecord 100.0%Succesfully downloaded train0477.tfrecord 265415819 bytes.\n",
            "Successfully downloaded train0477.tfrecord\n",
            "\n",
            "\n",
            "Downloading: train3220.tfrecord\n",
            ">> Downloading http://us.data.yt8m.org/2/frame/train/trainZ6.tfrecord 100.0%Succesfully downloaded train3220.tfrecord 283857236 bytes.\n",
            "Successfully downloaded train3220.tfrecord\n",
            "\n",
            "\n",
            "Downloading: train1087.tfrecord\n",
            ">> Downloading http://us.data.yt8m.org/2/frame/train/trainrH.tfrecord 100.0%Succesfully downloaded train1087.tfrecord 275012267 bytes.\n",
            "Successfully downloaded train1087.tfrecord\n",
            "\n",
            "\n",
            "Downloading: train0276.tfrecord\n",
            ">> Downloading http://us.data.yt8m.org/2/frame/train/traineC.tfrecord 100.0%Succesfully downloaded train0276.tfrecord 263558703 bytes.\n",
            "Successfully downloaded train0276.tfrecord\n",
            "\n",
            "\n",
            "Downloading: train1646.tfrecord\n",
            ">> Downloading http://us.data.yt8m.org/2/frame/train/trainAI.tfrecord 100.0%Succesfully downloaded train1646.tfrecord 258141008 bytes.\n",
            "Successfully downloaded train1646.tfrecord\n",
            "\n",
            "\n",
            "Downloading: train2495.tfrecord\n",
            ">> Downloading http://us.data.yt8m.org/2/frame/train/trainOp.tfrecord 100.0%Succesfully downloaded train2495.tfrecord 267357422 bytes.\n",
            "Successfully downloaded train2495.tfrecord\n",
            "\n",
            "\n",
            "All done. No more files to download.\n"
          ]
        }
      ],
      "source": [
        "# !mkdir -p ~/data/yt8m/frame; cd ~/data/yt8m/frame\n",
        "! curl data.yt8m.org/download.py | shard=1,300 partition=2/frame/train mirror=us python\n",
        "# !curl data.yt8m.org/download.py | shard=1,100 partition=2/frame/validate mirror=us python\n",
        "# !curl data.yt8m.org/download.py | shard=1,100 partition=2/frame/test mirror=us python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUqGLC_pe--m",
        "outputId": "158b70f1-d3e7-4905-ed75-99862dd849b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (2.5.1)\n",
            "Requirement already satisfied: transformers in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (4.47.1)\n",
            "Requirement already satisfied: opencv-python in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (4.10.0.84)\n",
            "Requirement already satisfied: tensorflow in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (2.18.0)\n",
            "Requirement already satisfied: librosa in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (0.10.2.post1)\n",
            "Requirement already satisfied: h5py in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (3.12.1)\n",
            "Requirement already satisfied: tqdm in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (2.0.2)\n",
            "Requirement already satisfied: Pillow in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (11.0.0)\n",
            "Requirement already satisfied: filelock in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (5.29.1)\n",
            "Requirement already satisfied: setuptools in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (3.7.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: rich in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! python -m venv venv\n",
        "! source venv/bin/activate\n",
        "! pip install torch transformers opencv-python tensorflow librosa h5py tqdm numpy Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: setuptools in /Users/aryansethi20/.pyenv/versions/3.11.6/lib/python3.11/site-packages (65.5.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! pip install setuptools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Eo3Iv_gGCTuQ"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CLIPProcessor, CLIPModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from typing import Dict, List, Generator, Union\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import h5py\n",
        "import multiprocessing\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from PIL import Image\n",
        "import logging\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ezgVzd2IXag6"
      },
      "outputs": [],
      "source": [
        "class YT8MDataset:\n",
        "    def __init__(self, data_dir: str):\n",
        "        self.data_dir = data_dir\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.tfrecord_files = self._get_tfrecord_files()\n",
        "\n",
        "    def _get_tfrecord_files(self) -> List[str]:\n",
        "        files = [os.path.join(self.data_dir, f) for f in os.listdir(self.data_dir)\n",
        "                if f.endswith('.tfrecord')]\n",
        "        self.logger.info(f\"Found {len(files)} TFRecord files\")\n",
        "        return files\n",
        "\n",
        "    def parse_tfrecord(self, example_proto):\n",
        "        context_features = {\n",
        "            'id': tf.io.FixedLenFeature([], tf.string),\n",
        "            'labels': tf.io.VarLenFeature(tf.int64)\n",
        "        }\n",
        "\n",
        "        sequence_features = {\n",
        "            'rgb': tf.io.FixedLenSequenceFeature([], tf.string),\n",
        "            'audio': tf.io.FixedLenSequenceFeature([], tf.string)\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            context, sequence = tf.io.parse_single_sequence_example(\n",
        "                example_proto,\n",
        "                context_features=context_features,\n",
        "                sequence_features=sequence_features\n",
        "            )\n",
        "\n",
        "            return context, sequence\n",
        "\n",
        "        except tf.errors.InvalidArgumentError as e:\n",
        "            self.logger.error(f\"Error parsing TFRecord: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def decode_features(self, parsed_data):\n",
        "        if parsed_data is None:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            context, sequence = parsed_data\n",
        "\n",
        "            # Decode video ID\n",
        "            video_id = context['id'].numpy().decode('utf-8')\n",
        "\n",
        "            # Decode labels\n",
        "            labels = tf.sparse.to_dense(context['labels']).numpy()\n",
        "\n",
        "            # Decode RGB and audio features\n",
        "            rgb_features = []\n",
        "            audio_features = []\n",
        "\n",
        "            for rgb_bytes in sequence['rgb']:\n",
        "                rgb_frame = np.frombuffer(rgb_bytes.numpy(), dtype=np.uint8)\n",
        "                rgb_frame = rgb_frame.reshape(-1, 1024)\n",
        "                rgb_features.append(rgb_frame)\n",
        "\n",
        "            for audio_bytes in sequence['audio']:\n",
        "                audio_frame = np.frombuffer(audio_bytes.numpy(), dtype=np.uint8)\n",
        "                audio_frame = audio_frame.reshape(-1, 128)\n",
        "                audio_features.append(audio_frame)\n",
        "\n",
        "            return {\n",
        "                'id': video_id,\n",
        "                'labels': labels,\n",
        "                'rgb': np.array(rgb_features),\n",
        "                'audio': np.array(audio_features)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error decoding features: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def __iter__(self) -> Generator:\n",
        "        for tfrecord_file in self.tfrecord_files:\n",
        "            self.logger.info(f\"Processing file: {tfrecord_file}\")\n",
        "            try:\n",
        "                dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
        "                for raw_record in dataset:\n",
        "                    features = self.parse_tfrecord(raw_record)\n",
        "                    decoded_features = self.decode_features(features)\n",
        "                    if decoded_features is not None:\n",
        "                        yield decoded_features\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error processing file {tfrecord_file}: {str(e)}\")\n",
        "                continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zf3M2H1kXdGo"
      },
      "outputs": [],
      "source": [
        "class MP4Processor:\n",
        "    def __init__(self, num_frames: int = 10):\n",
        "        self.num_frames = num_frames\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        self.inception_model = self.initialize_inception_model()\n",
        "\n",
        "    def initialize_inception_model(self):\n",
        "        inception_base = tf.keras.applications.InceptionV3(\n",
        "            include_top=False,\n",
        "            weights='imagenet',\n",
        "            input_shape=(299, 299, 3),\n",
        "            pooling='avg'\n",
        "        )\n",
        "        inception_base.trainable = False\n",
        "\n",
        "        model = tf.keras.Sequential([\n",
        "            inception_base,\n",
        "            tf.keras.layers.Dense(1024),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            tf.keras.layers.Activation('relu')\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "        return model\n",
        "\n",
        "    def extract_features(self, video_path: str) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Extract RGB and audio features from MP4 file\"\"\"\n",
        "        frames = self._extract_frames(video_path)\n",
        "        rgb_features = self._process_frames(frames)\n",
        "        audio_features = self._extract_audio(video_path)\n",
        "\n",
        "        return {\n",
        "            'rgb': rgb_features,\n",
        "            'audio': audio_features\n",
        "        }\n",
        "\n",
        "    def _extract_frames(self, video_path: str) -> List[np.ndarray]:\n",
        "        \"\"\"Extract evenly spaced frames from video\"\"\"\n",
        "        frames = []\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        frame_indices = np.linspace(0, total_frames-1, self.num_frames, dtype=int)\n",
        "\n",
        "        for idx in frame_indices:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frames.append(frame_rgb)\n",
        "\n",
        "        cap.release()\n",
        "        return frames\n",
        "\n",
        "    def _process_frames(self, frames: List[np.ndarray]) -> np.ndarray:\n",
        "        \"\"\"Process frames using InceptionV3 to match YouTube-8M format\"\"\"\n",
        "        processed_frames = []\n",
        "        for frame in frames:\n",
        "            try:\n",
        "                frame_resized = tf.image.resize(frame, (299, 299))\n",
        "                frame_preprocessed = tf.keras.applications.inception_v3.preprocess_input(\n",
        "                    frame_resized\n",
        "                )\n",
        "                frame_batch = tf.expand_dims(frame_preprocessed, 0)\n",
        "                features = self.inception_model(frame_batch, training=False)\n",
        "                features_normalized = tf.nn.l2_normalize(features, axis=1)\n",
        "                processed_frames.append(features_normalized[0])\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error processing frame: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if not processed_frames:\n",
        "            raise ValueError(\"No frames were successfully processed\")\n",
        "\n",
        "        return np.stack(processed_frames)\n",
        "\n",
        "    def _extract_audio(self, video_path: str) -> np.ndarray:\n",
        "        \"\"\"Extract audio features to match YouTube-8M format\"\"\"\n",
        "        y, sr = librosa.load(video_path, sr=16000, mono=True)\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=128)\n",
        "        mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
        "        return mfccs_scaled.reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZNqmSH9IXfrF"
      },
      "outputs": [],
      "source": [
        "class VideoCopyrightDetector:\n",
        "    def __init__(self, use_gpu: bool = True):\n",
        "        self.device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
        "        self.clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(self.device)\n",
        "        self.clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "        self.mp4_processor = MP4Processor()\n",
        "\n",
        "        self.visual_similarity_threshold = 0.85\n",
        "        self.audio_similarity_threshold = 0.85\n",
        "\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        self.embedding_cache = {}\n",
        "\n",
        "    def precompute_embeddings(self, dataset: YT8MDataset, cache_file: str = 'yt8m_embeddings_cache.h5'):\n",
        "        if os.path.exists(cache_file):\n",
        "            self.logger.info(\"Loading existing embedding cache...\")\n",
        "            with h5py.File(cache_file, 'r') as f:\n",
        "                for video_id in f.keys():\n",
        "                    self.embedding_cache[video_id] = {\n",
        "                        'visual': torch.tensor(f[video_id]['visual'][()]),\n",
        "                        'audio': torch.tensor(f[video_id]['audio'][()])\n",
        "                    }\n",
        "            return\n",
        "\n",
        "        self.logger.info(\"Precomputing embeddings for dataset...\")\n",
        "        with h5py.File(cache_file, 'w') as cache:\n",
        "            for features in tqdm(dataset):\n",
        "                video_id = features['id']\n",
        "                try:\n",
        "                    visual_embedding = torch.tensor(features['rgb'])\n",
        "                    audio_embedding = torch.tensor(features['audio'])\n",
        "\n",
        "                    video_group = cache.create_group(video_id)\n",
        "                    video_group.create_dataset('visual', data=visual_embedding.numpy())\n",
        "                    video_group.create_dataset('audio', data=audio_embedding.numpy())\n",
        "\n",
        "                    self.embedding_cache[video_id] = {\n",
        "                        'visual': visual_embedding,\n",
        "                        'audio': audio_embedding\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    self.logger.error(f\"Error processing video {video_id}: {str(e)}\")\n",
        "\n",
        "    def compare_mp4_with_dataset(self, mp4_path: str) -> List[Dict]:\n",
        "        self.logger.info(f\"Processing query video: {mp4_path}\")\n",
        "        query_features = self.mp4_processor.extract_features(mp4_path)\n",
        "\n",
        "        query_features = {\n",
        "            'id': os.path.basename(mp4_path),\n",
        "            'rgb': query_features['rgb'],\n",
        "            'audio': query_features['audio']\n",
        "        }\n",
        "\n",
        "        return self._compare_features(query_features)\n",
        "\n",
        "    def _compare_features(self, query_features: Dict) -> List[Dict]:\n",
        "        query_visual = torch.tensor(query_features['rgb']).to(self.device)\n",
        "        query_audio = torch.tensor(query_features['audio']).to(self.device)\n",
        "\n",
        "        results = []\n",
        "        with ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:\n",
        "            futures = []\n",
        "\n",
        "            for video_id, embeddings in self.embedding_cache.items():\n",
        "                future = executor.submit(\n",
        "                    self._compute_similarity,\n",
        "                    query_visual,\n",
        "                    query_audio,\n",
        "                    embeddings['visual'].to(self.device),\n",
        "                    embeddings['audio'].to(self.device),\n",
        "                    video_id\n",
        "                )\n",
        "                futures.append(future)\n",
        "\n",
        "            for future in tqdm(futures, desc=\"Comparing with dataset\"):\n",
        "                result = future.result()\n",
        "                if result['is_likely_copy']:\n",
        "                    results.append(result)\n",
        "\n",
        "        results.sort(key=lambda x: max(x['visual_similarity'], x['audio_similarity']),\n",
        "                    reverse=True)\n",
        "        return results\n",
        "\n",
        "    def _compute_similarity(self, query_visual, query_audio, dataset_visual, dataset_audio, video_id):\n",
        "    # Convert tensors to float for mean and similarity computations\n",
        "        query_visual = query_visual.float()\n",
        "        query_audio = query_audio.float()\n",
        "        dataset_visual = dataset_visual.float()\n",
        "        dataset_audio = dataset_audio.float()\n",
        "\n",
        "        visual_similarity = float(torch.nn.functional.cosine_similarity(\n",
        "            query_visual.mean(dim=0),\n",
        "            dataset_visual.mean(dim=0),\n",
        "            dim=0\n",
        "        ))\n",
        "\n",
        "        audio_similarity = float(torch.nn.functional.cosine_similarity(\n",
        "            query_audio.mean(dim=0),\n",
        "            dataset_audio.mean(dim=0),\n",
        "            dim=0\n",
        "        ))\n",
        "\n",
        "        return {\n",
        "            'video_id': video_id,\n",
        "            'visual_similarity': visual_similarity,\n",
        "            'audio_similarity': audio_similarity,\n",
        "            'is_likely_copy': (visual_similarity > self.visual_similarity_threshold or\n",
        "                             audio_similarity > self.audio_similarity_threshold),\n",
        "            'details': self._generate_similarity_details(visual_similarity, audio_similarity)\n",
        "        }\n",
        "\n",
        "\n",
        "    def _generate_similarity_details(self, visual_sim, audio_sim):\n",
        "        details = []\n",
        "        if visual_sim > self.visual_similarity_threshold:\n",
        "            details.append(f\"High visual similarity detected: {visual_sim:.2f}\")\n",
        "        if audio_sim > self.audio_similarity_threshold:\n",
        "            details.append(f\"High audio similarity detected: {audio_sim:.2f}\")\n",
        "        return details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_SzAJXiFe61L"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    try:\n",
        "        detector = VideoCopyrightDetector(use_gpu=True)\n",
        "\n",
        "        dataset_path = \"./\"\n",
        "        dataset = YT8MDataset(dataset_path)\n",
        "\n",
        "        detector.precompute_embeddings(dataset)\n",
        "\n",
        "        query_video_path = \"./test-video.mp4\"\n",
        "\n",
        "        results = detector.compare_mp4_with_dataset(query_video_path)\n",
        "\n",
        "        print(f\"\\nFound {len(results)} potential matches:\")\n",
        "        for result in results:\n",
        "            print(f\"\\nVideo ID: {result['video_id']}\")\n",
        "            print(f\"Visual Similarity: {result['visual_similarity']:.2f}\")\n",
        "            print(f\"Audio Similarity: {result['audio_similarity']:.2f}\")\n",
        "            print(\"Details:\", \"\\n\".join(result['details']))\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main execution: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "864k46Hhe7_M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-18 17:20:04,989 - ERROR - Error in main execution: [Errno 2] No such file or directory: '/content/'\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m detector \u001b[38;5;241m=\u001b[39m VideoCopyrightDetector(use_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mYT8MDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m detector\u001b[38;5;241m.\u001b[39mprecompute_embeddings(dataset)\n\u001b[1;32m     16\u001b[0m query_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/test-video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mYT8MDataset.__init__\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m      4\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(\n\u001b[1;32m      5\u001b[0m     level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtfrecord_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tfrecord_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mYT8MDataset._get_tfrecord_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_tfrecord_files\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m---> 12\u001b[0m     files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tfrecord\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m TFRecord files\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m files\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/'"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR6wuxTBGK6a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
